{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PyaPaQI-IEMh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.optim import Adam, SGD\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import copy\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) #mounting my google drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy-1V1GjKFGp",
        "outputId": "8b669170-b61a-462d-ca90-a4534617a536"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "p9in-fgbKL9g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/KAGGLE_API_CREDENTIALS/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "3lZGF4H3KOGW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "xjQ5nfwaKP4v"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d khoongweihao/covid19-xray-dataset-train-test-sets\n",
        "\n",
        "#link to dataset: https://www.kaggle.com/datasets/khoongweihao/covid19-xray-dataset-train-test-sets"
      ],
      "metadata": {
        "id": "KKUQBSZMKeRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/covid19-xray-dataset-train-test-sets.zip'"
      ],
      "metadata": {
        "id": "7x59c-g7KmWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' #setting up device agnostic code"
      ],
      "metadata": {
        "id": "1ar2ByweKRWZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((512,512)),  # Resize the image to (512,512)\n",
        "    transforms.RandomHorizontalFlip(),  # Flip the image horizontally\n",
        "    transforms.RandomRotation(20),  # Rotate the image by up to 20 degrees\n",
        "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image with the mean and std dev for ImageNet\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((512,512)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image with the mean and std dev for ImageNet\n",
        "])\n"
      ],
      "metadata": {
        "id": "-u5qe4zfKsPj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_path = '/content/xray_dataset_covid19/train'\n",
        "test_dataset_path = '/content/xray_dataset_covid19/test'\n",
        "\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_dataset_path, transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(test_dataset_path, transform=test_transform)\n"
      ],
      "metadata": {
        "id": "Xfczh7wlN8Lz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import RandomSampler\n",
        "BATCH_SIZE =32\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "Z0XS_YuyQdjR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, loss_fn, optimizer,device):\n",
        "    model.train()\n",
        "    running_loss = 0.0 #keeps track of the total loss in entire dataset\n",
        "    preds_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    for X, y in train_loader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X)\n",
        "        loss = loss_fn(outputs, y.float()) #the loss_fn expects the two params to be of the same dtype. y is an int. so we convert it to float\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get predictions\n",
        "\n",
        "        probs = torch.sigmoid(outputs)  # Apply sigmoid activation to get probabilities\n",
        "        preds = (probs > 0.5).float()  # Use threshold of 0.5 for classification\n",
        "\n",
        "\n",
        "        # Move predictions and labels to CPU and convert to numpy arrays, then append to the lists\n",
        "        preds_list.append(preds.detach().cpu().numpy())\n",
        "        labels_list.append(y.cpu().numpy())\n",
        "\n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "    # Concatenate all the numpy arrays into a single numpy array\n",
        "    all_preds = np.concatenate(preds_list, axis=0).astype(int)\n",
        "    all_labels = np.concatenate(labels_list, axis=0).astype(int)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)  # Use scikit-learn's accuracy_score\n",
        "\n",
        "    return epoch_loss, epoch_acc\n"
      ],
      "metadata": {
        "id": "TF4t-q1EQ-5Z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    preds_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(X)\n",
        "            loss = loss_fn(outputs, y.float())\n",
        "\n",
        "            # Get predictions\n",
        "            probs = torch.sigmoid(outputs)  # Apply sigmoid activation to get probabilities\n",
        "            preds = (probs > 0.5).float()  # Use threshold of 0.5 for classification\n",
        "\n",
        "            # Move predictions and labels to CPU and convert to numpy arrays, then append to the lists\n",
        "            preds_list.append(preds.detach().cpu().numpy())\n",
        "            labels_list.append(y.cpu().numpy())\n",
        "\n",
        "            running_loss += loss.item() * X.size(0)\n",
        "\n",
        "    # Concatenate all the numpy arrays into a single numpy array\n",
        "    all_preds = np.concatenate(preds_list, axis=0).astype(int)\n",
        "    all_labels = np.concatenate(labels_list, axis=0).astype(int)\n",
        "\n",
        "    epoch_loss = running_loss / len(test_loader.dataset)\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)  # Use scikit-learn's accuracy_score\n",
        "\n",
        "    classification_results = classification_report(all_labels, all_preds)\n",
        "\n",
        "    return epoch_loss, epoch_acc, classification_results\n"
      ],
      "metadata": {
        "id": "6JWtN51HR2NA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate(model, train_loader, test_loader, loss_fn, optimizer, epochs, device, model_save_path):\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, train_acc = train_model(model, train_loader, loss_fn, optimizer, device)\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "          test_loss, test_acc, class_report = test_model(model, test_loader, loss_fn, device)\n",
        "          print(f'Epoch {epoch+1}/{epochs},test Loss: {test_loss:.4f}, test Acc: {test_acc:.4f}')\n",
        "\n",
        "\n",
        "        # Save the model weights if this epoch gives us the highest test accuracy\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            torch.save(model.state_dict(), model_save_path)\n",
        "            best_class_report = class_report\n",
        "\n",
        "\n",
        "    # After all epochs, print the best classification report\n",
        "    print(\"Best Classification Report : \")\n",
        "    return best_class_report, best_acc"
      ],
      "metadata": {
        "id": "OyBJJ1S5TzF9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#i only did this to find the shape that my classifier layer would be receiving\n",
        "\n",
        "img,_ = train_dataset[59]\n",
        "\n",
        "resize_transform = transforms.Resize((512, 512))\n",
        "resized_img = resize_transform(img)\n",
        "\n",
        "conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3,out_channels = 6, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=6,out_channels = 6,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=6,out_channels = 12,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=12,out_channels = 12,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "conv_block_3 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=12,out_channels = 18,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=18,out_channels = 18,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "X = conv_block_1(resized_img)\n",
        "X = conv_block_2(X)\n",
        "X = conv_block_3(X)\n",
        "X.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyCeUI6wVGz_",
        "outputId": "be04e001-20c0-488f-a36e-e18b59b9dd72"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class COVID19_XRAY_CNNV2(nn.Module):\n",
        "  def __init__(self,input_shape,output_shape):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,out_channels = 6, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=6,out_channels = 6,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=6,out_channels = 12,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=12,out_channels = 12,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "    self.conv_block_3 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=12,out_channels = 18,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=18,out_channels = 18,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "    self.classifier_layer = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=73728, out_features=64),\n",
        "        nn.BatchNorm1d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=64, out_features=1)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.conv_block_1(X)\n",
        "    X = self.conv_block_2(X)\n",
        "    X = self.conv_block_3(X)\n",
        "    X = self.classifier_layer(X)\n",
        "    return X.squeeze(dim=1)\n"
      ],
      "metadata": {
        "id": "-61dPm4hfpGt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = COVID19_XRAY_CNNV2(input_shape=3,output_shape=1).to(device)"
      ],
      "metadata": {
        "id": "BeRlK_Oubnet"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = Adam(params=model.parameters(), lr=0.003, weight_decay=0.007)"
      ],
      "metadata": {
        "id": "aStt9wJUbzHj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "\n",
        "# Perform training and validation\n",
        "train_and_validate(model, train_loader, test_loader, loss_fn, optimizer, epochs, device, 'COVID19_XRAY_CNN_weights.pth')"
      ],
      "metadata": {
        "id": "-85Kh8S6b-Mf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}